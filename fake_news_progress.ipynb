{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPD2mLRh2yOFnvzNBeV2055"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import joblib\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","project_path = \"/content/drive/MyDrive/Fake News Project\"\n","\n","# Load classical models\n","lr_bfk = joblib.load(project_path + \"/lr_bharat.pkl\")\n","svm_bfk = joblib.load(project_path + \"/svm_bharat.pkl\")\n","tfidf_bfk = joblib.load(project_path + \"/tfidf_bharat.pkl\")\n","\n","# Load mBERT\n","model_bfk = AutoModelForSequenceClassification.from_pretrained(project_path + \"/mbert_bharat_model\")\n","tokenizer = AutoTokenizer.from_pretrained(project_path + \"/mbert_bharat_model\")\n","\n","print(\"Models loaded successfully!\")"],"metadata":{"id":"L_S1za78Hlio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------\n","# MOUNT GOOGLE DRIVE\n","# ---------------------------------------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"H5ni2tT_WLsO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------\n","# IMPORT REQUIRED LIBRARIES\n","# ---------------------------------------------------------\n","import pandas as pd\n","import numpy as np\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"XNXldfLsyXnv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------\n","# TEXT CLEANING FUNCTION (USED BY ALL DATASETS)\n","# ---------------------------------------------------------\n","\n","def clean_text(text):\n","    text = str(text).lower()\n","    text = re.sub(r\"http\\S+\", \"\", text)              # remove URLs\n","    text = re.sub(r\"[^a-zA-Z\\u0900-\\u097F ]\", \"\", text)  # keep English + Hindi chars\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text"],"metadata":{"id":"X-MRIYFhybju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["liar_path = \"/content/drive/MyDrive/Fake News Project/LIAR/train.tsv\"\n","\n","column_names = [\n","    \"id\",\"label\",\"statement\",\"subject\",\"speaker\",\"speaker_job\",\"state\",\"party\",\n","        \"barely_true_counts\",\"false_counts\",\"half_true_counts\",\"mostly_true_counts\",\n","            \"pants_on_fire_counts\",\"context\"\n","            ]\n","df = pd.read_csv(liar_path, sep=\"\\t\", header=None, names=column_names)\n","print(df[[\"label\",\"statement\"]].head())\n"],"metadata":{"id":"zvB6uT9oeCdC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[\"clean_text\"] = df[\"statement\"].apply(clean_text)"],"metadata":{"id":"83QFR9ljXAS-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tfidf_liar = TfidfVectorizer(max_features=3000)\n","X_liar = tfidf_liar.fit_transform(df[\"clean_text\"])\n","y_liar = df[\"label\"]\n","\n","print(\"LIAR TF-IDF Shape:\", X_liar.shape)"],"metadata":{"id":"xALcEH8uXAWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------\n","# LOAD FAKEDDIT DATASET\n","# ---------------------------------------------------------\n","fakeddit_path = \"/content/drive/MyDrive/Fake News Project/Fakeddit/multimodal_train.tsv\"\n","\n","fakeddit = pd.read_csv(fakeddit_path, sep=\"\\t\")\n","\n","print(\"Fakeddit Loaded:\", fakeddit.shape)\n","print(fakeddit.head())"],"metadata":{"id":"Pf0qJc-1XAY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cleaned text\n","fakeddit[\"clean_text\"] = fakeddit[\"clean_title\"].apply(clean_text)"],"metadata":{"id":"Rne0dd2vXAbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_fakeddit = fakeddit[\"6_way_label\"]\n","print(\"Unique Fakeddit 6-class labels:\", y_fakeddit.unique())"],"metadata":{"id":"CS1J9qLRblJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tfidf_fakeddit = TfidfVectorizer(max_features=3000)\n","X_fakeddit = tfidf_fakeddit.fit_transform(fakeddit[\"clean_text\"])\n","\n","print(\"Fakeddit TF-IDF shape:\", X_fakeddit.shape)"],"metadata":{"id":"yhWU1MPnXAeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------\n","# LOAD BHARATFAKENEWSKOSH\n","# ---------------------------------------------------------\n","\n","bfk_path = \"/content/drive/MyDrive/Fake News Project/BharatFakeNewsKosh/BharatFakeNewsKosh.xlsx\"\n","\n","bfk = pd.read_excel(bfk_path)\n","\n","print(\"BharatFakeNewsKosh Loaded:\", bfk.shape)\n","bfk.head()"],"metadata":{"id":"H6YjpdqRXAgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nLanguages:\", bfk[\"Language\"].unique())\n","print(\"\\nLabels:\", bfk[\"Label\"].unique())"],"metadata":{"id":"RZsIwpYEXAjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use English translation of the statement\n","bfk[\"clean_text\"] = bfk[\"Eng_Trans_Statement\"].apply(clean_text)\n","\n","print(\"\\nCleaned Sample:\")\n","print(bfk[[\"Eng_Trans_Statement\", \"clean_text\"]].head())"],"metadata":{"id":"jKT_Jyl9c9e1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tfidf_bfk = TfidfVectorizer(max_features=3000)\n","X_bfk = tfidf_bfk.fit_transform(bfk[\"clean_text\"])\n","\n","y_bfk = bfk[\"Label\"]\n","\n","print(\"Multilingual TF-IDF Shape:\", X_bfk.shape)"],"metadata":{"id":"NyrT_AGiXAmY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------\n","# TRAIN/TEST SPLITS FOR ALL 3 DATASETS\n","# ---------------------------------------------------------\n","\n","# 1️⃣ LIAR Dataset (Truthfulness Classification)\n","X_train_liar, X_test_liar, y_train_liar, y_test_liar = train_test_split(\n","    X_liar, y_liar, test_size=0.2, random_state=42\n",")\n","print(\"LIAR Train/Test Split:\")\n","print(\"Train:\", X_train_liar.shape)\n","print(\"Test:\", X_test_liar.shape)\n","print(\"\\n\")\n","\n","# 2️⃣ Fakeddit Dataset (Fake News Type Classification)\n","X_train_fak, X_test_fak, y_train_fak, y_test_fak = train_test_split(\n","    X_fakeddit, y_fakeddit, test_size=0.2, random_state=42\n",")\n","print(\"Fakeddit Train/Test Split:\")\n","print(\"Train:\", X_train_fak.shape)\n","print(\"Test:\", X_test_fak.shape)\n","print(\"\\n\")\n","\n","# 3️⃣ BharatFakeNewsKosh (Multilingual Fake News Classification)\n","X_train_bfk, X_test_bfk, y_train_bfk, y_test_bfk = train_test_split(\n","    X_bfk, y_bfk, test_size=0.2, random_state=42\n",")\n","print(\"BharatFakeNewsKosh Train/Test Split:\")\n","print(\"Train:\", X_train_bfk.shape)\n","print(\"Test:\", X_test_bfk.shape)"],"metadata":{"id":"5N0gUnnlXAp9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df[\"label\"].unique())\n"],"metadata":{"id":"u7G3NCNlaTE6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Create the model\n","lr_model = LogisticRegression(max_iter=1000)\n","\n","# Train the model\n","lr_model.fit(X_train_liar, y_train_liar)\n","\n","# Predict on test data\n","y_pred_lr = lr_model.predict(X_test_liar)\n","\n","# Show results\n","print(\"Accuracy:\", accuracy_score(y_test_liar, y_pred_lr))\n","print(\"\\nClassification Report:\\n\")\n","print(classification_report(y_test_liar, y_pred_lr))\n"],"metadata":{"id":"Hlz1x6fH9fPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Create SVM model\n","svm_model = LinearSVC(max_iter=5000)\n","\n","# Train the model\n","svm_model.fit(X_train_liar, y_train_liar)\n","\n","# Predict on test data\n","y_pred_svm = svm_model.predict(X_test_liar)\n","\n","# Show results\n","print(\"SVM Accuracy:\", accuracy_score(y_test_liar, y_pred_svm))\n","print(\"\\nClassification Report:\\n\")\n","print(classification_report(y_test_liar, y_pred_svm))"],"metadata":{"id":"J4NRSbKMo-WY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","lr_fakeddit = LogisticRegression(max_iter=1000)\n","lr_fakeddit.fit(X_train_fak, y_train_fak)\n","\n","y_pred_fakeddit = lr_fakeddit.predict(X_test_fak)\n","\n","print(\"Fakeddit Accuracy:\", accuracy_score(y_test_fak, y_pred_fakeddit))\n","print(classification_report(y_test_fak, y_pred_fakeddit))\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","\n","\n","lr_fakeddit = LogisticRegression(max_iter=1000)\n","\n","lr_fakeddit.fit(X_train_fak, y_train_fak)\n","\n","\n","\n","y_pred_fakeddit = lr_fakeddit.predict(X_test_fak)\n","\n","\n","\n","print(\"Fakeddit Accuracy:\", accuracy_score(y_test_fak, y_pred_fakeddit))\n","\n","print(classification_report(y_test_fak, y_pred_fakeddit))\n","\n"],"metadata":{"id":"0CwvwNKnAJp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fakeddit_label_map = {\n","      0: \"True\",\n","      1: \"Satire\",\n","      2: \"Misleading\",\n","      3: \"False\",\n","      4: \"Clickbait\",\n","      5: \"Propaganda\"\n","    }"],"metadata":{"id":"T6teQCewCNkb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_fake_type(text):\n","      cleaned = clean_text(text)\n","      vector = tfidf_fakeddit.transform([cleaned])\n","      pred_num = lr_fakeddit.predict(vector)[0]\n","      return fakeddit_label_map.get(pred_num, pred_num)"],"metadata":{"id":"MGBkXtE_DHFM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_truthfulness(text):\n","      cleaned = clean_text(text)\n","      vector = tfidf_liar.transform([cleaned])\n","      prediction = lr_model.predict(vector)\n","      return prediction[0]"],"metadata":{"id":"rYzM7ObvHfAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_input = input(\"Enter a news statement: \")\n","print(\"Truthfulness:\", predict_truthfulness(user_input))\n","print(\"Type:\", predict_fake_type(user_input))\n"],"metadata":{"id":"u9jn0vbnE9wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","lr_bfk = LogisticRegression(max_iter=1000)\n","lr_bfk.fit(X_train_bfk, y_train_bfk)\n","\n","y_pred_lr_bfk = lr_bfk.predict(X_test_bfk)\n","\n","print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_bfk, y_pred_lr_bfk))\n","print(classification_report(y_test_bfk, y_pred_lr_bfk))\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","\n","\n","lr_bfk = LogisticRegression(max_iter=1000)\n","\n","lr_bfk.fit(X_train_bfk, y_train_bfk)\n","\n","\n","\n","y_pred_lr_bfk = lr_bfk.predict(X_test_bfk)\n","\n","\n","\n","print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_bfk, y_pred_lr_bfk))\n","\n","print(classification_report(y_test_bfk, y_pred_lr_bfk))"],"metadata":{"id":"s9VUKPUHUvgh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.svm import LinearSVC\n","\n","svm_bfk = LinearSVC()\n","svm_bfk.fit(X_train_bfk, y_train_bfk)\n","\n","y_pred_svm_bfk = svm_bfk.predict(X_test_bfk)\n","\n","print(\"SVM Accuracy:\", accuracy_score(y_test_bfk, y_pred_svm_bfk))\n","print(classification_report(y_test_bfk, y_pred_svm_bfk))\n"],"metadata":{"id":"g-y0Qfe3XE18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["small_bfk = bfk.sample(n=6000, random_state=42).reset_index(drop=True)\n","\n","labels = small_bfk[\"Label\"].astype(\"category\")\n","label2id = {l:i for i,l in enumerate(labels.cat.categories)}\n","id2label = {i:l for l,i in label2id.items()}\n","\n","small_bfk[\"label_id\"] = labels.map(label2id)"],"metadata":{"id":"GVwoI_18YYdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","\n","dataset_bfk = Dataset.from_pandas(\n","    small_bfk[[\"Text\", \"label_id\"]].rename(columns={\"Text\": \"text\", \"label_id\": \"label\"})\n","    )\n","dataset_bfk = dataset_bfk.train_test_split(test_size=0.2)\n"],"metadata":{"id":"0LPG9yLbrtLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","\n","def tokenize(batch):\n","    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","    dataset_bfk = dataset_bfk.map(tokenize, batched=True)\n","    dataset_bfk.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"],"metadata":{"id":"sGj9AMvNtHhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification\n","\n","model_bfk = AutoModelForSequenceClassification.from_pretrained(\n","    \"bert-base-multilingual-cased\",\n","        num_labels=len(label2id),\n","            id2label=id2label,\n","                label2id=label2id\n","                )\n"],"metadata":{"id":"dT91RQdsuXGk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Re-tokenize properly\n","def tokenize(batch):\n","    return tokenizer(\n","            batch[\"text\"],\n","                    padding=\"max_length\",\n","                            truncation=True,\n","                                    max_length=128\n","                                        )\n","\n","dataset_bfk = dataset_bfk.map(tokenize, batched=True)\n","\n","dataset_bfk.set_format(\n","                                            type=\"torch\",\n","                                                columns=[\"input_ids\", \"attention_mask\", \"label\"]\n","                                                )\n","\n","                                                # Training\n","from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","                                                    output_dir=\"./mbbert_bharat\",\n","                                                        num_train_epochs=4,\n","                                                            per_device_train_batch_size=8,\n","                                                    learning_rate=2e-5,\n","                                                        weight_decay=0.01,\n","\n","                                                                logging_steps=100\n","                                                                )\n","trainer_bfk = Trainer(\n","                                                                    model=model_bfk,\n","                                                                        args=training_args,\n","                                                                            train_dataset=dataset_bfk[\"train\"],\n","                                                                                eval_dataset=dataset_bfk[\"test\"]\n","                                                                                )\n","\n","trainer_bfk.train()\n"],"metadata":{"id":"X1TxfRiHvmr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics = trainer_bfk.evaluate()\n","print(metrics)\n"],"metadata":{"id":"06Iv7yffz-L6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    acc = accuracy_score(labels, predictions)\n","    return {\"accuracy\": acc}\n"],"metadata":{"id":"92CLiis40nHN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from transformers import Trainer\n","\n","# Compute weights once using label_id\n","label_counts = small_bfk[\"label_id\"].value_counts().sort_index()\n","class_weights = torch.tensor(\n","    1.0 / label_counts.values,\n","        dtype=torch.float\n","        )\n","class_weights = class_weights / class_weights.sum()\n","\n","class WeightedTrainer(Trainer):\n","            def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","                    labels = inputs.get(\"labels\")\n","                    outputs = model(**inputs)\n","                    logits = outputs.get(\"logits\")\n","\n","                    loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(model.device))\n","                    loss = loss_fct(logits, labels)\n","\n","                    return (loss, outputs) if return_outputs else loss\n","\n","\n"],"metadata":{"id":"zTTnGKUHEm7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer_bfk = WeightedTrainer(\n","      model=model_bfk,\n","          args=training_args,\n","              train_dataset=dataset_bfk[\"train\"],\n","                  eval_dataset=dataset_bfk[\"test\"],\n","                      compute_metrics=compute_metrics\n","                      )"],"metadata":{"id":"PWwQpwVi0vHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer_bfk.train()"],"metadata":{"id":"Fw2flC8UADwC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer_bfk.evaluate()"],"metadata":{"id":"EyEuPOQ4AfKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import joblib\n","\n","project_path = \"/content/drive/MyDrive/Fake News Project\"\n","os.makedirs(project_path, exist_ok=True)\n","\n","# Save classical ML models\n","joblib.dump(lr_bfk, project_path + \"/lr_bharat.pkl\")\n","joblib.dump(svm_bfk, project_path + \"/svm_bharat.pkl\")\n","joblib.dump(tfidf_bfk, project_path + \"/tfidf_bharat.pkl\")\n","\n","# Save mBERT model\n","trainer_bfk.save_model(project_path + \"/mbert_bharat_model\")\n","tokenizer.save_pretrained(project_path + \"/mbert_bharat_model\")\n","\n","print(\"All models saved successfully!\")"],"metadata":{"id":"PUgq9XjPFC3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.listdir(\"/content/drive/MyDrive/Fake News Project\")"],"metadata":{"id":"k2P9a_pFFtV3"},"execution_count":null,"outputs":[]}]}